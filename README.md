# Empowering Topic Modeling with Large Language Models (LLMs):  
## A Comparative Study on Labeling Efficiency and Accuracy

This repository contains supplementary materials for our research paper **"Empowering Topic Modeling with Large Language Models (LLMs): A Comparative Study on Labeling Efficiency and Accuracy."** 

## Datasets

We used a privately gathered dataset, **the WorldCup2022 Hashtag Tweets dataset**, along with the following publicly available datasets:
- [BBC News Dataset](<http://mlg.ucd.ie/datasets/bbc.html>)
- [arXiv Abstracts Dataset](<https://www.kaggle.com/datasets/spsayakpaul/arxiv-paper-abstracts>)
- [Amazon Reviews Dataset](<https://amazon-reviews-2023.github.io/>)
- [20 Newsgroups Dataset](<https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html>)
- [WorldCup2022 Hashtag Tweets](<INSERT LINK HERE>)

## Appendix

The appendix file (`Appendix_Final_Table.pdf.pdf`) contains the final tables, including all topic labels generated by each generation method across the different datasets. These tables provide a comprehensive comparison of the labels produced by humans and various Large Language Models (LLMs).