# Empowering Topic Modeling with Large Language Models (LLMs):  
## A Comparative Study on Labeling Efficiency and Accuracy

This repository contains supplementary materials for our research paper **"Empowering Topic Modeling with Large Language Models (LLMs): A Comparative Study on Labeling Efficiency and Accuracy."** 

---
## Datasets

We used a privately gathered dataset, **the WorldCup2022 Hashtag Tweets dataset**, along with four publicly available datasets. Due to its large size, we are hosting the WorldCup dataset on Google Drive instead of GitHub. Below are the links to access all datasets:

- [BBC News Dataset](<http://mlg.ucd.ie/datasets/bbc.html>)
- [arXiv Abstracts Dataset](<https://www.kaggle.com/datasets/Cornell-University/arxiv?select=arxiv-metadata-oai-snapshot.json>) (Note: The arxiv abstracts dataset may be updated with more data.)
- [Amazon Reviews Dataset](<https://amazon-reviews-2023.github.io/>)
- [Newsgroups20 Dataset](<https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html>)
- [#WorldCup2022 Tweets](<https://drive.google.com/drive/folders/1VpltHjeGqNsM_QcnP7Q0D0qtiRYuzJVB?usp=sharing>) (Original CSV files before preprocessing.)

### Original and Preprocessed Datasets

All five datasets have been preprocessed following the methodology outlined in our paper. The cleaned and formatted versions are available in a separate Google Drive folder:

* [Preprocessed Datasets](<https://drive.google.com/drive/folders/13tgFNonUAIu-8Xxi86ljmZ6X5noIFoeh?usp=sharing>)

These preprocessed datasets are ready for direct use in experiments. You can load them using pandas for analysis and modeling.

---
## Experiment Files
This repository includes three key Python scripts that reproduce our **dataset preprocessing, topic modeling, and LLM-based topic labeling** workflows:
1. **`preprocess.py`** – This script processes each dataset according to the exact steps we followed in the paper. It handles text cleaning, stopword removal, and formatting to prepare the data for topic modeling.  

2. **`bertopic_workflow.py`** – This script applies **BERTopic** to generate topics from the preprocessed datasets. It follows the workflow used in the paper, including dimensionality reduction, clustering, and topic extraction.

3. **`llm_labeling_workflow.py`** – This script generates **topic labels** using Large Language Models (LLMs). It automates label generation for topics using **GPT-4o, Llama 3.1 8B Instruct, and Llama 3.2 3B Instruct**, following our paper's methodology. The script also includes a test function to run the labeling process. 

---
## Appendix

The appendix file (`Appendix_Final_Table.pdf`) contains the final tables, including all topic labels generated by each generation method across the different datasets. These tables provide a comprehensive comparison of the labels produced by humans and various Large Language Models (LLMs).