{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T05:20:19.386536Z",
     "start_time": "2024-11-12T05:20:18.720671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "bbc_news_topics = {\n",
    "    'topic 0': ['said', 'mr', 'would', 'government', 'labour', 'us', 'also', 'year', 'election', 'new', 'blair', 'people', 'minister', 'party', 'could'],\n",
    "    'topic 1': ['club', 'chelsea', 'united', 'arsenal', 'liverpool', 'league', 'game', 'football', 'manager', 'manchester', 'said', 'cup', 'players', 'would', 'goal'],\n",
    "    'topic 2': ['film', 'best', 'actor', 'films', 'director', 'awards', 'award', 'actress', 'oscar', 'festival', 'movie', 'aviator', 'said', 'year', 'star'],\n",
    "    'topic 3': ['england', 'wales', 'ireland', 'rugby', 'france', 'nations', 'six', 'game', 'side', 'coach', 'robinson', 'players', 'scotland', 'italy', 'first'],\n",
    "    'topic 4': ['music', 'band', 'album', 'song', 'best', 'number', 'rock', 'singer', 'chart', 'one', 'said', 'us', 'awards', 'top', 'pop'],\n",
    "    'topic 5': ['open', 'roddick', 'seed', 'australian', 'match', 'set', 'win', 'nadal', 'tennis', 'first', '63', 'beat', 'hewitt', 'final', 'federer'],\n",
    "    'topic 6': ['broadband', 'phone', 'mobile', 'people', 'phones', 'bt', 'said', 'net', 'tv', 'services', 'service', 'uk', 'digital', 'mobiles', 'million'],\n",
    "    'topic 7': ['security', 'virus', 'software', 'users', 'email', 'spam', 'microsoft', 'said', 'site', 'windows', 'net', 'attacks', 'viruses', 'data', 'spyware'],\n",
    "    'topic 8': ['olympic', 'race', 'indoor', 'world', 'champion', 'holmes', 'championships', 'athens', 'european', 'radcliffe', 'marathon', '60m', 'title', 'record', 'best'],\n",
    "    'topic 9': ['games', 'game', 'gaming', 'nintendo', 'gamers', 'xbox', 'ds', 'video', 'sony', 'titles', 'console', 'play', 'said', 'halo', 'time'],\n",
    "    'topic 10': ['show', 'tv', 'series', 'bbc', 'said', 'channel', 'comedy', 'television', 'audience', 'viewers', 'celebrity', 'us', 'also', 'programme', 'million'],\n",
    "    'topic 11': ['music', 'files', 'digital', 'said', 'technology', 'p2p', 'players', 'bittorrent', 'filesharing', 'apple', 'networks', 'software', 'people', 'piracy', 'peertopeer'],\n",
    "    'topic 12': ['gadgets', 'gadget', 'digital', 'technology', 'technologies', 'show', 'devices', 'people', 'electronics', 'sony', 'mobile', 'consumer', 'video', 'make', 'laptop'],\n",
    "    'topic 13': ['search', 'google', 'blogs', 'web', 'yahoo', 'blog', 'people', 'users', 'microsoft', 'jeeves', 'information', 'ask', 'desktop', 'said', 'internet'],\n",
    "    'topic 14': ['kenteris', 'iaaf', 'thanou', 'greek', 'drugs', 'conte', 'athens', 'doping', 'test', 'tests', 'olympics', 'balco', 'athletes', 'athletics', 'banned']\n",
    "}\n",
    "\n",
    "arxiv_abstracts_topics = {\n",
    "    'topic 0': ['mass', 'ray', 'energy', 'model', 'observations', 'data', '10', 'star', 'emission', 'high', 'observed', 'galaxies', 'stars', 'dark', 'solar'],\n",
    "    'topic 1': ['learning', 'data', 'training', 'based', 'model', 'neural', 'image', 'models', 'methods', 'performance', 'network', 'method', 'propose', 'images', 'deep'],\n",
    "    'topic 2': ['spin', 'quantum', 'magnetic', 'graphene', 'phase', 'field', 'temperature', 'states', 'state', 'two', 'energy', 'electron', 'transition', 'density', 'model'],\n",
    "    'topic 3': ['group', 'graph', 'prove', 'algebra', 'groups', 'graphs', 'show', 'algebras', 'finite', 'number', 'let', 'paper', 'every', 'give', 'set'],\n",
    "    'topic 4': ['theory', 'black', 'gauge', 'quark', 'hole', 'field', 'pi', 'string', 'brane', 'decays', 'qcd', 'scalar', 'theories', 'mass', 'two'],\n",
    "    'topic 5': ['random', 'stochastic', 'time', 'model', 'networks', 'process', 'network', 'distribution', 'processes', 'probability', 'dynamics', 'show', 'results', 'study', 'two'],\n",
    "    'topic 6': ['solutions', 'equation', 'equations', 'prove', 'space', 'spaces', 'existence', 'paper', 'solution', 'boundary', 'infinity', 'problem', 'operator', 'type', 'case'],\n",
    "    'topic 7': ['learning', 'algorithm', 'policy', 'control', 'problem', 'algorithms', 'reinforcement', 'agent', 'rl', 'optimal', 'optimization', 'agents', 'robot', 'based', 'reward'],\n",
    "    'topic 8': ['method', 'numerical', 'problems', 'convergence', 'problem', 'methods', 'order', 'algorithm', 'convex', 'element', 'optimization', 'finite', 'linear', 'solution', 'error'],\n",
    "    'topic 9': ['quantum', 'classical', 'states', 'qubit', 'state', 'qubits', 'entanglement', 'algorithm', 'circuit', 'error', 'protocol', 'key', 'circuits', 'gates', 'qkd'],\n",
    "    'topic 10': ['liquid', 'dynamics', 'model', 'phase', 'simulations', 'surface', 'stress', 'transition', 'granular', 'shear', 'two', 'energy', 'temperature', 'particles', 'fluid'],\n",
    "    'topic 11': ['channel', 'codes', 'mimo', 'interference', 'multiple', 'proposed', 'performance', 'rate', 'power', 'user', 'wireless', 'communication', 'paper', 'users', 'capacity'],\n",
    "    'topic 12': ['privacy', 'data', 'federated', 'blockchain', 'fl', 'performance', 'learning', 'network', 'security', 'based', 'paper', 'clients', 'model', 'private', 'attacks'],\n",
    "    'topic 13': ['optical', 'photon', 'quantum', 'mode', 'light', 'frequency', 'photonic', 'states', 'modes', 'nonlinear', 'two', 'phase', 'single', 'wave', 'state'],\n",
    "    'topic 14': ['regression', 'data', 'estimator', 'estimators', 'treatment', 'causal', 'estimation', 'distribution', 'model', 'bayesian', 'methods', 'inference', 'method', 'proposed', 'sample'],\n",
    "    'topic 15': ['plasma', 'turbulence', 'flow', 'turbulent', 'magnetic', 'velocity', 'field', 'reynolds', 'simulations', 'energy', 'scale', 'fluid', 'plasmas', 'numerical', 'flows'],\n",
    "    'topic 16': ['software', 'code', 'students', 'research', 'ai', 'development', 'learning', 'based', 'data', 'citation', 'paper', 'developers', 'process', 'science', 'study'],\n",
    "    'topic 17': ['clustering', 'data', 'algorithm', 'tree', 'phylogenetic', 'trees', 'hashing', 'algorithms', 'time', 'problem', 'based', 'persistence', 'methods', 'distance', 'space'],\n",
    "    'topic 18': ['power', 'grid', 'system', 'energy', 'voltage', 'battery', 'renewable', 'proposed', 'control', 'electricity', 'load', 'charging', 'demand', 'storage', 'model'],\n",
    "    'topic 19': ['traffic', 'vehicles', 'vehicle', 'driving', 'lane', 'model', 'autonomous', 'prediction', 'road', 'time', 'based', 'pedestrian', 'flow', 'network', 'trajectory'],\n",
    "    'topic 20': ['imaging', 'resolution', 'microscopy', 'image', 'phase', 'images', 'optical', 'ultrasound', 'diffraction', 'light', 'speckle', 'method', 'reconstruction', 'high', 'scattering'],\n",
    "    'topic 21': ['withdrawn', 'paper', 'author', 'comment', 'authors', 'phys', 'due', 'university', 'reply', 'arxiv', 'rev', 'professor', 'lett', 'error', 'cond'],\n",
    "    'topic 22': ['fractional', 'derivative', 'order', 'caputo', 'derivatives', 'numerical', 'equations', 'differential', 'method', 'time', 'equation', 'scheme', 'solution', 'alpha', 'calculus'],\n",
    "    'topic 23': ['players', 'team', 'player', 'teams', 'sports', 'football', 'game', 'league', 'soccer', 'season', 'games', 'performance', 'basketball', 'data', 'matches'],\n",
    "    'topic 24': ['localization', 'indoor', 'positioning', 'accuracy', 'based', 'location', 'fingerprinting', 'wifi', 'rss', 'fingerprint', 'signal', 'uwb', 'wireless', 'rssi', 'proposed']\n",
    "}\n",
    "\n",
    "# amazon_reviews_topics = {\n",
    "#     'topic 0': ['case', 'ipad', 'tablet', 'keyboard', 'kindle', 'screen', 'mouse', 'cover', 'it', 'like', 'one', 'great', 'love', 'use', 'would'],\n",
    "#     'topic 1': ['sound', 'great', 'quality', 'good', 'speakers', 'speaker', 'music', 'radio', 'headphones', 'alexa', 'one', 'use', 'like', 'bluetooth', 'echo'],\n",
    "#     'topic 2': ['bag', 'great', 'stand', 'laptop', 'good', 'sturdy', 'price', 'backpack', 'love', 'quality', 'easy', 'well', 'monitor', 'product', 'it'],\n",
    "#     'topic 3': ['drive', 'card', 'fan', 'laptop', 'usb', 'computer', 'fans', 'one', 'memory', 'drives', 'great', 'use', 'it', 'works', 'sd'],\n",
    "#     'topic 4': ['router', 'antenna', 'wifi', 'watch', 'signal', 'get', 'channels', 'one', 'modem', 'gps', 'garmin', 'would', 'time', 'house', 'internet'],\n",
    "#     'topic 5': ['product', 'gift', 'great', 'loves', 'it', 'fast', 'working', 'bought', 'works', 'shipping', 'one', 'good', 'worked', 'months', 'stopped'],\n",
    "#     'topic 6': ['camera', 'lens', 'cameras', 'tripod', 'great', 'use', 'quality', 'good', 'one', 'pictures', 'get', 'would', 'it', 'like', 'picture'],\n",
    "#     'topic 7': ['cable', 'cables', 'cord', 'power', 'plug', 'cords', 'great', 'one', 'works', 'wire', 'good', 'work', 'well', 'quality', 'switch'],\n",
    "#     'topic 8': ['tv', 'remote', 'projector', 'hdmi', 'picture', 'one', 'cable', 'great', 'works', 'fire', 'screen', 'use', 'roku', 'it', 'stick'],\n",
    "#     'topic 9': ['works', 'great', 'product', 'love', 'advertised', 'perfect', 'good', 'it', 'worked', 'perfectly', 'exactly', 'thanks', 'thank', 'fine', 'described'],\n",
    "#     'topic 10': ['tv', 'mount', 'easy', 'install', 'light', 'wall', 'great', 'lights', 'screws', 'works', 'product', 'one', 'would', 'mounting', 'well'],\n",
    "#     'topic 11': ['battery', 'batteries', 'charger', 'charge', 'charging', 'laptop', 'camera', 'one', 'original', 'charged', 'replacement', 'great', 'life', 'works', 'charges'],\n",
    "#     'topic 12': ['printer', 'print', 'ink', 'use', 'easy', 'instructions', 'printing', 'hp', 'cartridges', 'scanner', 'cartridge', 'great', 'works', 'product', 'work'],\n",
    "#     'topic 13': ['stickers', 'label', 'air', 'bubbles', 'clean', 'cleaning', 'dust', 'labels', 'sticker', 'product', 'adhesive', 'stick', 'great', 'use', 'tape'],\n",
    "#     'topic 14': ['band', 'fitbit', 'bands', 'comfortable', 'original', 'love', 'watch', 'colors', 'wear', 'fit', 'like', 'one', 'great', 'wrist', 'color'],\n",
    "#     'topic 15': ['water', 'waterproof', 'shower', 'camera', 'underwater', 'pool', 'speaker', 'great', 'use', 'swimming', 'sound', 'fish', 'pictures', 'good', 'snorkeling'],\n",
    "#     'topic 16': ['expected', 'works', 'expectations', 'met', 'everything', 'expectation', 'meet', 'exceeded', 'exactly', 'expect', 'hoped', 'be', 'pleased', 'thank', 'expecting'],\n",
    "#     'topic 17': ['needed', 'neededreturned', 'neededused', 'honored', 'kiddo', 'fo', 'ii', 'fair', 'thats', 'today', 'ok', 'too', 'all', 'pretty', 'that'],\n",
    "#     'topic 18': ['dislike', 'nothing', 'dislikes', 'disliked', 'product', 'anything', 'hate', 'liked', 'it', 'like', 'love', 'everything', 'dont', 'works', 'item'],\n",
    "#     'topic 19': ['supposed', 'do', 'to', 'product', 'says', 'does', 'exactly', 'good', 'price', 'suppose', 'great', 'works', 'buy', 'quality', 'intended']\n",
    "# }\n",
    "\n",
    "amazon_reviews_topics_retrain = {\n",
    "    'topic -1': ['great', 'sound', 'good', 'use', 'one', 'quality', 'works', 'like', 'would', 'product', 'it', 'well', 'work', 'camera', 'get'],\n",
    "    'topic 0': ['keyboard', 'mouse', 'router', 'one', 'monitor', 'wifi', 'cable', 'use', 'great', 'works', 'work', 'keys', 'it', 'would', 'like'],\n",
    "    'topic 1': ['sound', 'radio', 'great', 'quality', 'good', 'antenna', 'one', 'music', 'headphones', 'alexa', 'use', 'get', 'like', 'would', 'echo'],\n",
    "    'topic 2': ['case', 'tablet', 'kindle', 'ipad', 'screen', 'cover', 'it', 'like', 'love', 'one', 'great', 'fire', 'would', 'fits', 'use'],\n",
    "    'topic 3': ['battery', 'charge', 'charger', 'watch', 'batteries', 'charging', 'cord', 'phone', 'one', 'great', 'gps', 'cords', 'use', 'garmin', 'works'],\n",
    "    'topic 4': ['camera', 'lens', 'cameras', 'tripod', 'great', 'it', 'use', 'one', 'good', 'quality', 'get', 'would', 'well', 'like', 'video'],\n",
    "    'topic 5': ['bag', 'great', 'backpack', 'price', 'good', 'love', 'quality', 'color', 'laptop', 'well', 'product', 'nice', 'sturdy', 'cover', 'works'],\n",
    "    'topic 6': ['works', 'great', 'love', 'product', 'expected', 'perfect', 'advertised', 'good', 'it', 'needed', 'thanks', 'exactly', 'worked', 'perfectly', 'thank'],\n",
    "    'topic 7': ['drive', 'fan', 'card', 'laptop', 'fans', 'computer', 'ssd', 'one', 'drives', 'case', 'memory', 'power', 'ram', 'great', 'it'],\n",
    "    'topic 8': ['product', 'fast', 'working', 'great', 'shipping', 'months', 'works', 'stopped', 'arrived', 'item', 'worked', 'delivery', 'one', 'service', 'work'],\n",
    "    'topic 9': ['tv', 'remote', 'projector', 'picture', 'hdmi', 'one', 'fire', 'great', 'roku', 'cable', 'stick', 'screen', 'use', 'amazon', 'quality'],\n",
    "    'topic 10': ['easy', 'install', 'set', 'use', 'great', 'works', 'setup', 'product', 'instructions', 'up', 'assemble', 'good', 'installation', 'it', 'installed'],\n",
    "    'topic 11': ['mount', 'tv', 'stand', 'wall', 'monitor', 'desk', 'screws', 'sturdy', 'easy', 'monitors', 'mounting', 'one', 'great', 'would', 'bracket'],\n",
    "    'topic 12': ['band', 'fitbit', 'bands', 'strap', 'wrist', 'watch', 'comfortable', 'love', 'ties', 'like', 'one', 'fit', 'wear', 'original', 'great'],\n",
    "    'topic 13': ['stickers', 'air', 'label', 'bubbles', 'clean', 'dust', 'product', 'sticker', 'great', 'labels', 'plastic', 'cleaning', 'stick', 'adhesive', 'use'],\n",
    "    'topic 14': ['light', 'lights', 'bulb', 'bright', 'lamp', 'lighting', 'led', 'use', 'one', 'great', 'brightness', 'bulbs', 'easy', 'ring', 'like'],\n",
    "    'topic 15': ['fit', 'fits', 'perfect', 'perfectly', 'great', 'well', 'looks', 'good', 'works', 'install', 'head', 'product', 'easy', 'harness', 'nice'],\n",
    "    'topic 16': ['water', 'waterproof', 'shower', 'camera', 'underwater', 'pool', 'speaker', 'great', 'swimming', 'use', 'sound', 'fish', 'pictures', 'snorkeling', 'good'],\n",
    "    'topic 17': ['printer', 'print', 'ink', 'printing', 'hp', 'cartridges', 'scanner', 'cartridge', 'printers', 'prints', 'paper', 'printed', 'work', 'one', 'epson'],\n",
    "    'topic 18': ['protection', 'lock', 'security', 'protective', 'protects', 'protect', 'good', 'great', 'locks', 'product', 'system', 'well', 'home', 'it', 'price'],\n",
    "    'topic 19': ['dislike', 'nothing', 'dislikes', 'disliked', 'product', 'anything', 'hate', 'liked', 'it', 'like', 'love', 'everything', 'dont', 'fact', 'works']\n",
    "}\n",
    "\n",
    "\n",
    "newsgroup20_topics = {\n",
    "    'topic 0': ['game', 'team', 'year', 'games', 'hockey', 'players', 'season', 'play', 'writes', 'baseball', 'last', 'league', 'win', 'player', 'would'],\n",
    "    'topic 1': ['israel', 'people', 'one', 'writes', 'would', 'article', 'god', 'israeli', 'jews', 'think', 'say', 'arab', 'believe', 'it', 'right'],\n",
    "    'topic 2': ['drive', 'scsi', 'card', 'windows', 'disk', 'modem', 'ide', 'drives', 'controller', 'use', 'problem', 'dos', 'hard', 'system', 'bus'],\n",
    "    'topic 3': ['gun', 'people', 'would', 'fbi', 'guns', 'think', 'fire', 'president', 'writes', 'article', 'batf', 'one', 'koresh', 'government', 'right'],\n",
    "    'topic 4': ['windows', 'window', 'jpeg', 'file', 'image', 'use', 'files', 'color', 'graphics', 'program', 'display', 'gif', 'version', 'os', 'format'],\n",
    "    'topic 5': ['space', 'launch', 'nasa', 'orbit', 'earth', 'would', 'shuttle', 'moon', 'solar', 'mission', 'spacecraft', 'satellite', 'writes', 'lunar', 'like'],\n",
    "    'topic 6': ['key', 'encryption', 'clipper', 'chip', 'keys', 'government', 'privacy', 'security', 'escrow', 'use', 'des', 'nsa', 'would', 'secure', 'algorithm'],\n",
    "    'topic 7': ['sale', '00', 'offer', 'price', 'shipping', 'please', 'asking', 'condition', 'drive', 'mail', 'new', 'cd', 'sell', '10', 'interested'],\n",
    "    'topic 8': ['bike', 'dod', 'writes', 'dog', 'ride', 'article', 'riding', 'motorcycle', 'like', 'helmet', 'get', 'bikes', 'one', 'car', 'front'],\n",
    "    'topic 9': ['msg', 'patients', 'medical', 'disease', 'doctor', 'food', 'cancer', 'treatment', 'one', 'candida', 'pain', 'yeast', 'health', '92', 'vitamin'],\n",
    "    'topic 10': ['god', 'jesus', 'bible', 'christ', 'church', 'one', 'would', 'mary', 'christian', 'heaven', 'hell', 'people', 'faith', 'sin', 'believe'],\n",
    "    'topic 11': ['car', 'cars', 'engine', 'ford', 'dealer', 'writes', 'price', 'article', 'new', 'mustang', 'oil', 'would', 'like', 'miles', 'one'],\n",
    "    'topic 12': ['mail', 'address', 'comp', 'list', 'gopher', 'ftp', 'software', 'please', 'email', 'system', 'group', 'space', 'files', 'graphics', 'mac'],\n",
    "    'topic 13': ['printer', 'print', 'fonts', 'hp', 'font', 'deskjet', 'printers', 'laser', 'ink', 'windows', 'printing', 'postscript', 'use', 'paper', 'truetype'],\n",
    "    'topic 14': ['armenian', 'turkish', 'armenians', 'armenia', 'turks', 'turkey', 'people', 'said', 'soviet', 'azerbaijan', 'genocide', 'greek', 'russian', 'one', 'greece'],\n",
    "    'topic 15': ['radar', 'detector', 'detectors', 'car', 'receiver', 'alarm', 'radio', 'would', 'use', 'one', 'get', 'transmitter', 'antenna', 'valentine', 'writes'],\n",
    "    'topic 16': ['polygon', 'points', 'algorithm', 'polygons', 'sphere', 'line', 'problem', 'lines', 'point', 'plane', 'surface', 'routine', 'p1', 'convex', 'xxxx'],\n",
    "    'topic 17': ['insurance', 'health', 'private', 'care', 'canada', 'geico', 'canadian', 'system', 'coverage', 'doctors', 'hospital', 'medical', 'pay', 'americans', 'writes'],\n",
    "    'topic 18': ['monitor', 'tempest', 'power', 'monitors', 'computer', 'computers', 'hours', 'turn', 'electricity', 'day', '24', 'equipment', 'pick', 'emissions', 'consumption'],\n",
    "    'topic 19': ['battery', 'concrete', 'batteries', 'discharge', 'acid', 'lead', 'temperature', 'floor', 'dirt', 'reaction', 'heat', 'stored', 'electrolyte', 'terminals', 'garage'],\n",
    "    'topic 20': ['cpu', 'fan', 'heat', 'sink', 'fans', 'power', 'chip', 'idle', 'cooling', 'hot', 'computationally', 'running', 'intensive', 'case', 'supply'],\n",
    "    'topic 21': ['photography', 'kirlian', 'pictures', 'krillean', 'leaf', 'aura', 'object', 'corona', 'spelling', 'energy', 'involves', 'taking', 'sci', 'plates', 'huey'],\n",
    "    'topic 22': ['blue', 'uv', 'boards', 'leds', 'light', 'led', 'green', 'solder', 'mask', 'bulb', 'emit', 'board', 'bulbs', 'colour', 'seen'],\n",
    "    'topic 23': ['cancer', 'cholesterol', 'medical', 'circumcision', 'diet', 'health', 'pregnancy', 'teacher', 'drug', 'fat', 'disease', 'biology', 'sperm', 'risk', 'birth'],\n",
    "    'topic 24': ['paint', 'wax', 'finish', 'car', 'scratches', 'rowlands', 'lisa', 'buff', 'dull', 'plastic', 'good', 'scuffed', 'fiance', 'bike', 'black']\n",
    "}\n",
    "\n",
    "worldcup_tweets_topics = {\n",
    "    'topic 0': ['cup', 'world', 'worldcup', 'rt', 'team', '2022', 'fifa', 'qatar', 'live', 'win', 'nft', 'football', 'worldcup2022', 'join', 'championship'],\n",
    "    'topic 1': ['amp', 'follow', 'hours', 'proof', 'rt', 'join', '24', 'international', 'icc', '100', '40rt', '80', '40', '24350', '477'],\n",
    "    'topic 2': ['optout', 'reply', 'thanks', 'unsubscribe', 'fifaworldcuponfox', 'tweet', 'crazyfootballongotv', 'usa', 'playing', 'optingin', 'well', 'biggest', 'stop', 'enjoy', 'tournament'],\n",
    "    'topic 3': ['airdrop', '000', 'token', '10', 'airdrops', 'join', '120', 'lfg', 'fb', 'biggest', 'msp', 'metasports', 'msg', 'us', 'progress'],\n",
    "    'topic 4': ['katara', 'hayya', 'karwa', 'fiverr', 'aang', 'zuko', 'editing', 'khor', 'photo', 'arhbo', 'studios', 'card', 'directed', 'fi', 'light'],\n",
    "    'topic 5': ['prediction', 'share', 'nftplayer', 'constantly', 'project', 'para', 'vote', 'voting', 'update', 'latest', 'world', 'score', 'make', 'nft', 'football'],\n",
    "    'topic 6': ['mls', 'series', 'phillies', 'philadelphia', 'union', 'lose', 'bowl', 'philly', 'super', 'day', 'tough', 'eagles', 'lost', 'fans', 'superbowl'],\n",
    "    'topic 7': ['x7', 'x8', 'x4', 'x3', 'league', 'rey', 'champions', 'del', 'pr', 'club', 'liga', 'copa', 'european', 'la', 'sure'],\n",
    "    'topic 8': ['concentration', 'camps', 'poster', '1978', 'arg', 'calling', 'protest', 'french', 'boycott', 'no', 'football', 'rt', 'cup', 'world', 'coba'],\n",
    "    'topic 9': ['lecturing', 'urging', 'morality', 'written', 'focus', 'part', 'teams', 'tournament', 'fifa', 'rt', 'cup', 'world', 'dr', 'moralsk', 'overg'],\n",
    "    'topic 10': ['dapp', 'gttooneychain', 'immersion', 'tooneychain', 'introduction', 'environment', 'thread', 'better', 'rt', 'nws', 'vry', 'thy', 'signal', 'pump', 'announced'],\n",
    "    'topic 11': ['gunathilaka', 'danushka', 'sri', 'assault', 'sexual', 'cricketer', 'sydney', 'arrested', 'lankan', 'lanka', 'charged', 'rape', 'alleged', 't20', 'danushkagunathilaka'],\n",
    "    'topic 12': ['fiverr', 'editing', 'photo', 'careem', 'webdesign', 'graphicdesign', 'removal', 'satisfaction', 'photography', 'guarantee', 'background', 'sharp', 'contact', 'service', 'amazing'],\n",
    "    'topic 13': ['virat', 'ponting', 'kohli', 'said', 'ricky', 'rauf', 'talked', 'remembered', 'trem', 'haris', 'six', 'looked', 'brings', 'knew', 'asia'],\n",
    "    'topic 14': ['vinyl', 'vinylcollection', 'vinylcommunity', 'groovevinylstore', 'vintage', 'records', 'music', 'groovevinyl', 'imacelebrity', 'nowspinning', 'imaceleb', 'blackfriday', 'via', 'vinylrecords', 'thursdayvibes']\n",
    "}\n",
    "\n",
    "bbc_news_description = 'The dataset used comprised of 2,225 bbc news articles from the time of 2004-2005. The articles cover across five news categories: business, entertainment, politics, sport, and tech.'\n",
    "\n",
    "arxiv_description = 'This dataset comprises 2,521,247 abstracts of scientific articles from the arXiv repository, summarizing research across disciplines such as physics, computer science, mathematics, statistics, electrical engineering, quantitative biology, and economics. The content is highly technical and research-focused, providing concise summaries of complex studies.'\n",
    "\n",
    "amazon_reviews_description = 'This dataset contains user-generated reviews from the electronics category on Amazon, featuring opinions, ratings, and experiences related to various electronic products. The reviews reflect consumer feedback on product quality, performance, and usability.'\n",
    "\n",
    "news_description = 'The 20 Newsgroups dataset comprises 18,846 documents from various Usenet newsgroups collected between 1993 and 1994. These documents span 20 different topics, ranging from technical discussions to social commentary and debates on a wide array of subjects.'\n",
    "\n",
    "worldcup_description = 'This dataset consists of 2,407,396 tweets collected using the WorldCup2022 hashtag on Twitter, spanning from November 1, 2022, to January 9, 2023.'\n",
    "\n",
    "topic_dicts = [(\"bbc_news\", bbc_news_topics, bbc_news_description), (\"arxiv_abstracts\", arxiv_abstracts_topics, arxiv_description), (\"amazon_reviews\", amazon_reviews_topics_retrain, amazon_reviews_description), (\"newsgroup20\", newsgroup20_topics, news_description), (\"worldcup_tweets\", worldcup_tweets_topics, worldcup_description)]"
   ],
   "id": "de5723f239ce1efe",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T05:20:22.376307Z",
     "start_time": "2024-11-12T05:20:19.402025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Cuda can be used\")\n",
    "else:\n",
    "    print(\"Cuda is not available\")"
   ],
   "id": "562ed0c9dc2b891b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda can be used\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Parameters To Try\n",
    "\n",
    "* num_beams (int, optional, defaults to 1) — Number of beams for beam search. 1 means no beam search.\n",
    "* temperature (float, optional, defaults to 1.0) — The value used to module the next token probabilities.\n",
    "* top_k (int, optional, defaults to 50) — The number of highest probability vocabulary tokens to keep for top-k-filtering.\n",
    "\n",
    "### Temperature:\n",
    "Purpose: Controls the randomness of predictions by scaling the logits before applying softmax. Lower values make the model more deterministic, while higher values introduce more randomness.\n",
    "Suggested Range:\n",
    "Low: 0.2 (more deterministic)\n",
    "Medium: 0.5 (balance between randomness and determinism)\n",
    "High: 1.0 (more random and creative)\n",
    "Very High: 1.5 (very random, might be less coherent)\n",
    "\n",
    "### Top-k Sampling:\n",
    "Purpose: Limits the sampling pool to the top k most likely next tokens. Higher values allow for more creativity, while lower values make the output more focused.\n",
    "Suggested Range:\n",
    "k = 0 (no top-k sampling, uses all possible tokens)\n",
    "k = 10 (top 10 tokens)\n",
    "k = 50 (top 50 tokens)\n",
    "k = 100 (top 100 tokens)\n",
    "\n",
    "When top_k = 0:\n",
    "* This essentially means that no top-k sampling is applied. The model will always pick the token with the highest probability (greedy sampling). It’s like saying, “always choose the most likely next word without considering alternatives.”\n",
    "* Outcome: The generated text will be very deterministic, with little to no variation if you run the same prompt multiple times. This can lead to repetitive or less creative outputs, especially in more complex or open-ended tasks.\n",
    "\n",
    "When top_k > 0:\n",
    "* In this scenario, the model considers the top k tokens with the highest probability for each step in the sequence. It then samples from this subset of tokens rather than always choosing the one with the highest probability. For example, with top_k = 100, the model will sample from the top 100 most likely tokens at each step.\n",
    "* Outcome: This introduces more variability and creativity in the generated text. By considering a larger pool of potential next tokens, the model can produce more diverse and nuanced outputs. This is particularly useful in tasks where multiple valid continuations of a sentence or phrase are possible.\n",
    "\n",
    "### Beam Search (num_beams):\n",
    "Purpose: Beam search generates multiple sequences and selects the best one based on overall probability. Higher beam numbers allow for more exploration but are computationally expensive.\n",
    "Suggested Range:\n",
    "Low: 3 beams (faster, less diverse)\n",
    "Medium: 5 beams (a good balance)\n",
    "High: 10 beams (more thorough, slower)\n",
    "\n",
    "  \n",
    "### How Temperature Works in Sampling\n",
    "Temperature:\n",
    "Temperature scales the logits (the raw output scores from the model before applying softmax) before they are converted into probabilities. The formula for adjusting logits with temperature is typically:\n",
    "* $adjusted_logits = \\frac{logits}{temeprature}$\n",
    " \n",
    "Low Temperature (< 1.0): Makes the probability distribution sharper. The model becomes more confident in its predictions, making the most likely tokens even more probable. As a result, the sampling becomes more deterministic, often choosing the highest-probability token.\n",
    "High Temperature (> 1.0): Flattens the probability distribution. This increases the likelihood of choosing less probable tokens, making the sampling process more random and creative.\n",
    "Temperature = 1.0: The logits are unchanged, and the sampling process reflects the raw probabilities directly."
   ],
   "id": "5b77f2986ccb6db8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Llama 3.1 8B Instruct Model",
   "id": "bf496e917e16a342"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-12T05:20:50.795108Z",
     "start_time": "2024-11-12T05:20:22.561833Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "llama3_1_8b_token = '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'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", token=llama3_1_8b_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3.1-8B-Instruct\", token=llama3_1_8b_token).to('cuda')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f4f41606255434884716ef528c03a43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T05:33:19.680471Z",
     "start_time": "2024-11-12T05:20:50.825942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_generated_labels_llama3 = {}\n",
    "\n",
    "system_message = \"You are an expert topic modeler. You are tasked with generating a topic label that is both clear and contextually relevant, accurately reflecting the theme of a topic based on its keywords. {dataset_description} Your label should succinctly capture the essence of the topic, considering the broader context of the dataset while remaining focused and precise. The label should be clear, concise (not too long), and descriptive, encapsulating the core subject of the topic in a way that is easily understood. \"\n",
    "\n",
    "user_message = \"The keywords for this topic are: {topic_keywords}. Provide a label that best captures the theme of the topic suggested by these keywords. Provide one label only with no additional text.\"\n",
    "\n",
    "for topic_name, topic, dataset_description in topic_dicts:\n",
    "    llm_generated_labels_llama3[topic_name] = {}\n",
    "    for topic_num, topic_keywords in topic.items():\n",
    "            \n",
    "        formatted_system_message = system_message.format(dataset_description=dataset_description)\n",
    "        formatted_user_message = user_message.format(topic_keywords=', '.join(topic_keywords))\n",
    "\n",
    "        prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "            \n",
    "{formatted_system_message}<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{formatted_user_message}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "    \n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        output = model.generate(**input_ids, max_new_tokens=30, pad_token_id=tokenizer.eos_token_id, temperature=0.5)\n",
    "        text = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "            \n",
    "        # extract just the assistant's response, excluding the prompt\n",
    "        assistant_index = text.find(\"assistant\")\n",
    "        if assistant_index != -1:\n",
    "            text = text[assistant_index + len(\"Assistant:\"):].strip()\n",
    "            \n",
    "        llm_generated_labels_llama3[topic_name][topic_num] = text\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"Dataset\": dataset, \"Topic\": topic, \"Label\": label}\n",
    "    for dataset, topics in llm_generated_labels_llama3.items()\n",
    "    for topic, label in topics.items()\n",
    "])\n",
    "            \n",
    "# filepath = f'llama_3_1_8b_instruct_label_results_final_not_too_long_updated_user.csv'\n",
    "# df.to_csv(filepath, index=False)\n",
    "    "
   ],
   "id": "7c81741f3f332f1b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxny\\anaconda3\\envs\\topic_model_research2\\lib\\site-packages\\transformers\\models\\llama\\modeling_llama.py:655: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Meta Llama 3.2 3B Instruct",
   "id": "e2caf92e85a872d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T05:33:34.000348Z",
     "start_time": "2024-11-12T05:33:19.729587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "llama3_token = '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'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", token=llama3_token)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\", token=llama3_token).to('cuda')"
   ],
   "id": "3b4e8210b4b1ab26",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e4f6b2109d24de68614bf55ea1394a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d3eab29ee8ed48629d07292ea0607d7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T05:46:19.569887Z",
     "start_time": "2024-11-12T05:33:34.047806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm_generated_labels_llama3 = {}\n",
    "\n",
    "system_message = \"You are an expert topic modeler. You are tasked with generating a topic label that is both clear and contextually relevant, accurately reflecting the theme of a topic based on its keywords. {dataset_description} Your label should succinctly capture the essence of the topic, considering the broader context of the dataset while remaining focused and precise. The label should be clear, concise (not too long), and descriptive, encapsulating the core subject of the topic in a way that is easily understood. \"\n",
    "\n",
    "user_message = \"The keywords for this topic are: {topic_keywords}. Provide a label that best captures the theme of the topic suggested by these keywords. Provide one label only with no additional text.\"  \n",
    "for topic_name, topic, dataset_description in topic_dicts:\n",
    "    llm_generated_labels_llama3[topic_name] = {}\n",
    "    for topic_num, topic_keywords in topic.items():\n",
    "            \n",
    "        formatted_system_message = system_message.format(dataset_description=dataset_description)\n",
    "        formatted_user_message = user_message.format(topic_keywords=', '.join(topic_keywords))\n",
    "\n",
    "        prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "            \n",
    "{formatted_system_message}<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{formatted_user_message}<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\"\"\"\n",
    "\n",
    "    \n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        output = model.generate(**input_ids, max_new_tokens=30, pad_token_id=tokenizer.eos_token_id, temperature=0.5)\n",
    "        text = tokenizer.decode(output[0], skip_special_tokens=True).strip()\n",
    "            \n",
    "        # extract just the assistant's response, excluding the prompt\n",
    "        assistant_index = text.find(\"assistant\")\n",
    "        if assistant_index != -1:\n",
    "            text = text[assistant_index + len(\"Assistant:\"):].strip()\n",
    "            \n",
    "        llm_generated_labels_llama3[topic_name][topic_num] = text\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"Dataset\": dataset, \"Topic\": topic, \"Label\": label}\n",
    "    for dataset, topics in llm_generated_labels_llama3.items()\n",
    "    for topic, label in topics.items()\n",
    "])\n",
    "            \n",
    "# filepath = f'llama_3_1_3b_instruct_label_results_final_not_too_long_updated_user.csv'\n",
    "# df.to_csv(filepath, index=False)\n",
    "    "
   ],
   "id": "a400be67ab02c482",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gpt-4o ",
   "id": "7a7987c70e7dcf48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T05:46:20.292748Z",
     "start_time": "2024-11-12T05:46:19.601215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='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')"
   ],
   "id": "f04c31a913115ba9",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T05:47:05.106359Z",
     "start_time": "2024-11-12T05:46:20.325085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_message = \"You are an expert topic modeler. You are tasked with generating a topic label that is both clear and contextually relevant, accurately reflecting the theme of a topic based on its keywords. {dataset_description} Your label should succinctly capture the essence of the topic, considering the broader context of the dataset while remaining focused and precise. The label should be clear, concise (not too long), and descriptive, encapsulating the core subject of the topic in a way that is easily understood. \"\n",
    "\n",
    "user_message = \"The keywords for this topic are: {topic_keywords}. Provide a label that best captures the theme of the topic suggested by these keywords. Provide one label only with no additional text.\"\n",
    "# saying not too long after concise worked\n",
    "\n",
    "llm_generated_labels_gpt4o = {}\n",
    "        \n",
    "for topic_name, topic, dataset_description in topic_dicts:\n",
    "        \n",
    "    llm_generated_labels_gpt4o[topic_name] = {}\n",
    "        \n",
    "    for topic_num, topic_keywords in topic.items():\n",
    "            \n",
    "        formatted_system_message = system_message.format(dataset_description=dataset_description)\n",
    "        formatted_user_message = user_message.format(topic_keywords=', '.join(topic_keywords))\n",
    "            \n",
    "        output = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": formatted_system_message},\n",
    "                {\"role\": \"user\", \"content\": formatted_user_message}\n",
    "            ]).choices[0].message.content\n",
    "            \n",
    "        llm_generated_labels_gpt4o[topic_name][topic_num] = output\n",
    "            \n",
    "df = pd.DataFrame([\n",
    "    {\"Dataset\": dataset, \"Topic\": topic, \"Label\": label}\n",
    "    for dataset, topics in llm_generated_labels_gpt4o.items()\n",
    "    for topic, label in topics.items()\n",
    "])\n",
    "    \n",
    "# df.to_csv(f'gpt4o_labels_results_2_not_too_long_updated_user.csv', index=False)"
   ],
   "id": "6a669e15f1ba688e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T12:27:34.108012Z",
     "start_time": "2024-10-13T12:27:34.093463Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4fe3894a90b378c7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
